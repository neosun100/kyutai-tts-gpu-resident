# Kyutai TTS Docker éƒ¨ç½²æŒ‡å—

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

- âœ… **ä¸‰ç§è®¿é—®æ¨¡å¼**: UI ç•Œé¢ + REST API + MCP å·¥å…·
- âœ… **è‡ªåŠ¨ GPU é€‰æ‹©**: è‡ªåŠ¨é€‰æ‹©æ˜¾å­˜å ç”¨æœ€å°‘çš„ GPU
- âœ… **æ™ºèƒ½æ˜¾å­˜ç®¡ç†**: ç©ºé—²è‡ªåŠ¨é‡Šæ”¾ï¼Œæ”¯æŒæ‰‹åŠ¨é‡Šæ”¾
- âœ… **å¤šè¯­è¨€æ”¯æŒ**: ä¸­æ–‡/è‹±æ–‡ç•Œé¢åˆ‡æ¢
- âœ… **å®æ—¶çŠ¶æ€ç›‘æ§**: GPU ä½¿ç”¨æƒ…å†µå®æ—¶æ˜¾ç¤º
- âœ… **å®Œæ•´ API æ–‡æ¡£**: Swagger è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®å¯åŠ¨

```bash
./start.sh
```

å¯åŠ¨è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. æ£€æµ‹ NVIDIA é©±åŠ¨
2. é€‰æ‹©æœ€ç©ºé—²çš„ GPU
3. æ£€æŸ¥ç«¯å£å¯ç”¨æ€§
4. æ„å»º Docker é•œåƒ
5. å¯åŠ¨æœåŠ¡

### æ‰‹åŠ¨å¯åŠ¨

```bash
# 1. å¤åˆ¶ç¯å¢ƒå˜é‡é…ç½®
cp .env.example .env

# 2. ç¼–è¾‘é…ç½®ï¼ˆå¯é€‰ï¼‰
nano .env

# 3. é€‰æ‹© GPU å¹¶å¯åŠ¨
export NVIDIA_VISIBLE_DEVICES=2  # ä½¿ç”¨ GPU 2
docker-compose up -d
```

## ğŸ“ è®¿é—®åœ°å€

å¯åŠ¨åå¯é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®ï¼š

- **UI ç•Œé¢**: http://0.0.0.0:8900
- **API æ–‡æ¡£**: http://0.0.0.0:8900/apidocs
- **å¥åº·æ£€æŸ¥**: http://0.0.0.0:8900/health

## ğŸ¨ ä½¿ç”¨æ–¹å¼

### æ–¹å¼ä¸€ï¼šWeb UI

1. æ‰“å¼€æµè§ˆå™¨è®¿é—® http://0.0.0.0:8900
2. è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬
3. é€‰æ‹©éŸ³è‰²ï¼ˆå¯é€‰ï¼‰
4. è°ƒæ•´å‚æ•°ï¼ˆå¯é€‰ï¼‰
5. ç‚¹å‡»"ç”Ÿæˆè¯­éŸ³"
6. æ’­æ”¾æˆ–ä¸‹è½½ç”Ÿæˆçš„éŸ³é¢‘

**UI åŠŸèƒ½**ï¼š
- å®æ—¶ GPU çŠ¶æ€æ˜¾ç¤º
- æ‰‹åŠ¨é‡Šæ”¾æ˜¾å­˜æŒ‰é’®
- ä¸­è‹±æ–‡ç•Œé¢åˆ‡æ¢
- å‚æ•°å®æ—¶è°ƒæ•´
- éŸ³é¢‘åœ¨çº¿æ’­æ”¾

### æ–¹å¼äºŒï¼šREST API

#### ç”Ÿæˆè¯­éŸ³

```bash
curl -X POST http://0.0.0.0:8900/api/tts \
  -F "text=Hello, this is a test." \
  -F "cfg_coef=2.0" \
  --output output.wav
```

#### æŸ¥çœ‹ GPU çŠ¶æ€

```bash
curl http://0.0.0.0:8900/api/gpu/status
```

#### é‡Šæ”¾ GPU æ˜¾å­˜

```bash
curl -X POST http://0.0.0.0:8900/api/gpu/offload
```

#### Python ç¤ºä¾‹

```python
import requests

# ç”Ÿæˆè¯­éŸ³
response = requests.post(
    'http://0.0.0.0:8900/api/tts',
    data={
        'text': 'Hello, world!',
        'cfg_coef': 2.0
    }
)

with open('output.wav', 'wb') as f:
    f.write(response.content)

# æŸ¥çœ‹ GPU çŠ¶æ€
status = requests.get('http://0.0.0.0:8900/api/gpu/status').json()
print(f"GPU Memory: {status['memory_used_gb']}GB")
```

### æ–¹å¼ä¸‰ï¼šMCP å·¥å…·

è¯¦è§ [MCP_GUIDE.md](MCP_GUIDE.md)

```python
# é€šè¿‡ MCP å®¢æˆ·ç«¯è°ƒç”¨
result = await mcp_client.call_tool(
    "text_to_speech",
    {
        "text": "Hello from MCP!",
        "output_path": "/tmp/output.wav"
    }
)
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

| å˜é‡ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `PORT` | 8900 | æœåŠ¡ç«¯å£ |
| `DEVICE` | cuda | è®¾å¤‡ç±»å‹ |
| `GPU_IDLE_TIMEOUT` | 60 | GPU ç©ºé—²è¶…æ—¶ï¼ˆç§’ï¼‰ |
| `NVIDIA_VISIBLE_DEVICES` | 0 | ä½¿ç”¨çš„ GPU ID |
| `HF_REPO` | kyutai/tts-1.6b | æ¨¡å‹ä»“åº“ |
| `VOICE_REPO` | kyutai/tts-voices | éŸ³è‰²ä»“åº“ |
| `DEFAULT_VOICE` | expresso/... | é»˜è®¤éŸ³è‰² |

### å‚æ•°è¯´æ˜

#### cfg_coef (CFG Coefficient)
- **èŒƒå›´**: 1.0 - 3.0
- **é»˜è®¤**: 2.0
- **è¯´æ˜**: æ§åˆ¶ç”Ÿæˆè´¨é‡ï¼Œå€¼è¶Šé«˜è´¨é‡è¶Šå¥½ä½†å¯èƒ½è¿‡æ‹Ÿåˆ

#### voice (éŸ³è‰²)
- **é»˜è®¤**: expresso/ex03-ex01_happy_001_channel1_334s.wav
- **è¯´æ˜**: å¯åœ¨ [kyutai/tts-voices](https://huggingface.co/kyutai/tts-voices) æŸ¥çœ‹æ‰€æœ‰å¯ç”¨éŸ³è‰²

## ğŸ”§ ç®¡ç†å‘½ä»¤

```bash
# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down

# é‡å¯æœåŠ¡
docker-compose restart

# æŸ¥çœ‹å®¹å™¨çŠ¶æ€
docker-compose ps

# è¿›å…¥å®¹å™¨
docker-compose exec kyutai-tts bash

# æŸ¥çœ‹ GPU ä½¿ç”¨
nvidia-smi
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### GPU æ˜¾å­˜ç®¡ç†

1. **è‡ªåŠ¨é‡Šæ”¾**: ç©ºé—² 60 ç§’åè‡ªåŠ¨é‡Šæ”¾ï¼ˆå¯é€šè¿‡ `GPU_IDLE_TIMEOUT` è°ƒæ•´ï¼‰
2. **æ‰‹åŠ¨é‡Šæ”¾**: UI ç‚¹å‡»"é‡Šæ”¾æ˜¾å­˜"æˆ–è°ƒç”¨ API `/api/gpu/offload`
3. **æŒ‰éœ€åŠ è½½**: é¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½æ¨¡å‹ï¼Œåç»­è¯·æ±‚å¤ç”¨

### å¤š GPU éƒ¨ç½²

```bash
# å¯åŠ¨å¤šä¸ªå®ä¾‹åœ¨ä¸åŒ GPU ä¸Š
NVIDIA_VISIBLE_DEVICES=0 PORT=8900 docker-compose up -d
NVIDIA_VISIBLE_DEVICES=1 PORT=8901 docker-compose up -d
NVIDIA_VISIBLE_DEVICES=2 PORT=8902 docker-compose up -d
```

### è´Ÿè½½å‡è¡¡

ä½¿ç”¨ Nginx è¿›è¡Œè´Ÿè½½å‡è¡¡ï¼š

```nginx
upstream kyutai_tts {
    server 127.0.0.1:8900;
    server 127.0.0.1:8901;
    server 127.0.0.1:8902;
}

server {
    listen 80;
    location / {
        proxy_pass http://kyutai_tts;
    }
}
```

## ğŸ› æ•…éšœæ’æŸ¥

### æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
huggingface-cli download kyutai/tts-1.6b
huggingface-cli download kyutai/tts-voices
```

### GPU æ˜¾å­˜ä¸è¶³

```bash
# æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µ
nvidia-smi

# é‡Šæ”¾æ˜¾å­˜
curl -X POST http://0.0.0.0:8900/api/gpu/offload

# æˆ–é‡å¯å®¹å™¨
docker-compose restart
```

### ç«¯å£è¢«å ç”¨

```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
ss -tuln | grep 8900

# ä½¿ç”¨å…¶ä»–ç«¯å£
PORT=8901 docker-compose up -d
```

### å®¹å™¨æ— æ³•å¯åŠ¨

```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
docker-compose logs

# æ£€æŸ¥ nvidia-docker
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# é‡æ–°æ„å»º
docker-compose build --no-cache
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### å®æ—¶ç›‘æ§

```bash
# GPU ä½¿ç”¨ç›‘æ§
watch -n 1 nvidia-smi

# å®¹å™¨èµ„æºç›‘æ§
docker stats kyutai-tts

# æ—¥å¿—ç›‘æ§
docker-compose logs -f --tail=100
```

### æ—¥å¿—ä½ç½®

- **å®¹å™¨æ—¥å¿—**: `docker-compose logs`
- **è¾“å‡ºæ–‡ä»¶**: `./outputs/`
- **æ¨¡å‹ç¼“å­˜**: `~/.cache/huggingface/`

## ğŸ”’ å®‰å…¨å»ºè®®

1. **ç”Ÿäº§ç¯å¢ƒ**: æ·»åŠ è®¤è¯ä¸­é—´ä»¶
2. **é˜²ç«å¢™**: é™åˆ¶è®¿é—® IP
3. **HTTPS**: ä½¿ç”¨åå‘ä»£ç†æ·»åŠ  SSL
4. **èµ„æºé™åˆ¶**: è®¾ç½® Docker èµ„æºé™åˆ¶

```yaml
# docker-compose.yml æ·»åŠ èµ„æºé™åˆ¶
deploy:
  resources:
    limits:
      cpus: '4'
      memory: 16G
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [MCP ä½¿ç”¨æŒ‡å—](MCP_GUIDE.md)
- [åŸé¡¹ç›® README](README.md)
- [Kyutai TTS å®˜ç½‘](https://kyutai.org/next/tts)
- [API æ–‡æ¡£](http://0.0.0.0:8900/apidocs)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

- Python ä»£ç : MIT License
- Rust ä»£ç : Apache License
- æ¨¡å‹æƒé‡: CC-BY 4.0
